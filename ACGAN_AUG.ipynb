{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b62dae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Miniconda3\\envs\\dl\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "    - seaborn\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  h5py               pkgs/main/win-64::h5py-3.6.0-py39h3de5c98_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl            conda-forge::openssl-1.1.1p-h8ffe710_0 --> pkgs/main::openssl-1.1.1q-h2bbff1b_0\n",
      "  pandas                               1.4.2-py39hd77b12b_0 --> 1.4.3-py39hd77b12b_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.6.1~ --> pkgs/main::ca-certificates-2022.4.26-haa95532_0\n",
      "  certifi            conda-forge::certifi-2022.6.15-py39hc~ --> pkgs/main::certifi-2022.6.15-py39haa95532_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Rolling back transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/win-64::dipy==1.5.0=py39hb0a1f21_1\n",
      "  - conda-forge/noarch::h5io==0.1.7=pyh8a188c0_0\n",
      "  - conda-forge/noarch::mne==1.0.3=hd8ed1ab_1\n",
      "  - conda-forge/noarch::nibabel==3.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nilearn==0.9.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pymatreader==0.0.30=pyhd8ed1ab_0\n",
      "ERROR conda.core.link:_execute(730): An error occurred while installing package 'defaults::openssl-1.1.1q-h2bbff1b_0'.\n",
      "\n",
      "[Errno 13] Permission denied: 'D:\\\\Miniconda3\\\\envs\\\\dl\\\\Library\\\\bin\\\\libssl-1_1-x64.dll'\n",
      "()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370513dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\miniconda3\\envs\\dl\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: torchsummary in d:\\miniconda3\\envs\\dl\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\miniconda3\\envs\\dl\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: torchviz in d:\\miniconda3\\envs\\dl\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: utils in d:\\miniconda3\\envs\\dl\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: imageio in d:\\miniconda3\\envs\\dl\\lib\\site-packages (2.19.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: torch in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from torchviz) (1.11.0)\n",
      "Requirement already satisfied: graphviz in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from torchviz) (0.16)\n",
      "Requirement already satisfied: pillow>=8.3.2 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from imageio) (9.0.1)\n",
      "Requirement already satisfied: typing_extensions in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from torch->torchviz) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python torchsummary scikit-learn torchviz utils imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6a2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import utils\n",
    "import time\n",
    "from torch.nn.functional import one_hot\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf2ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sm_37', 'sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'compute_37'] cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_arch_list(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8079c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tqdm import notebook\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc\n",
    "import matplotlib.colors as mat_color\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "from torchvision.datasets import ImageNet, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "import imageio\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb59879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "        self.ReLU = nn.ReLU(True)\n",
    "        self.Tanh = nn.Tanh()\n",
    "        self.conv1 = nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 8, ngf * 8, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(ngf * 4)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm4 = nn.BatchNorm2d(ngf * 2)\n",
    "        \n",
    "        self.conv5 = nn.ConvTranspose2d(ngf * 2, ngf * 1, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm5 = nn.BatchNorm2d(ngf * 1)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose2d(ngf * 1, nc, 4, 2, 1, bias=False)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.BatchNorm1(x)\n",
    "        x = self.ReLU(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.BatchNorm2(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.BatchNorm3(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.BatchNorm4(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.BatchNorm5(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        output = self.Tanh(x)\n",
    "        return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, ndf, nc, nb_label):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.DropOut1 = nn.Dropout(p=0.5)\n",
    "        self.DropOut2 = nn.Dropout(p=0.25)\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(ndf)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4_1 = nn.Conv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm4_1 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4_2 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm4_2 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv4_3 = nn.Conv2d(ndf * 8, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.BatchNorm4_3 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, ndf * 1, 4, 1, 0, bias=False)\n",
    "        self.disc_linear = nn.Linear(ndf * 1, 1)\n",
    "        self.aux_linear = nn.Linear(ndf * 1, nb_label)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.ndf = ndf\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.conv1(input)\n",
    "        x = self.BatchNorm1(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.DropOut2(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.BatchNorm2(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.DropOut2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.BatchNorm3(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.DropOut2(x)\n",
    "\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.BatchNorm4_2(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.DropOut2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.BatchNorm4_3(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.DropOut2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1, self.ndf * 1)\n",
    "        c = self.aux_linear(x)\n",
    "        c = self.softmax(c)\n",
    "        s = self.disc_linear(x)\n",
    "        s = self.sigmoid(s)\n",
    "        return s, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b174419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation(path, num):\n",
    "    images = []\n",
    "    for e in range(num):\n",
    "        img_name = path + '_generate_animation_epoch%03d' % (e+1) + '.png'\n",
    "        images.append(imageio.imread(img_name))\n",
    "    imageio.mimsave(path + '_generate_animation.gif', images, fps=5)\n",
    "\n",
    "def loss_plot(hist, path='Train_hist', model_name = ''):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    plt.plot(x, hist['D_losses'], label='D_losses')\n",
    "    plt.plot(x, hist['G_losses'], label='G_losses')\n",
    "\n",
    "    plt.xlabel('Iter')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    path = os.path.join(path, model_name + '_loss.png')\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    image = np.squeeze(merge(images, size))\n",
    "    print(\"image saved at ->\", path)\n",
    "    return imageio.imwrite(path, image)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    if (images.shape[3] in (3,4)):\n",
    "        c = images.shape[3]\n",
    "        img = np.zeros((h * size[0], w * size[1], c))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "        return img\n",
    "    elif images.shape[3]==1:\n",
    "        img = np.zeros((h * size[0], w * size[1]))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
    "        return img\n",
    "    else:\n",
    "        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73154b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACGAN(object):\n",
    "    def __init__(self):\n",
    "        self.model_name = 'ACGAN'\n",
    "        self.I_want_to_train_faster = 10\n",
    "        self.num_epoch = round(12800/self.I_want_to_train_faster)\n",
    "        self.base_path = './data'\n",
    "        self.base_folder = \"Covid-19 Image Dataset\"\n",
    "        self.classic_folder = 'Coivd-19_Hist'\n",
    "        self.synthetic_folder = 'Coivd-19_Synthetic'\n",
    "        self.data_dir = os.path.join(self.base_path, self.classic_folder)\n",
    "        self.batch_size = 64\n",
    "        self.train_path = os.path.join(self.data_dir, \"train\")\n",
    "        self.test_path = os.path.join(self.data_dir, \"test\")\n",
    "        self.labels = os.listdir(self.train_path)\n",
    "        self.no_norm = mat_color.Normalize(vmin=0, vmax=255, clip=False)\n",
    "        self.label_dict = {\n",
    "            i : self.labels[i]\n",
    "            for i in range(len(self.labels))\n",
    "        }\n",
    "        self.img_size = 128\n",
    "        self.num_of_ch = 3\n",
    "        # size of z latent vector (i.e. size of generator input)\n",
    "        self.size_of_z = 512\n",
    "        self.num_of_label = len(self.labels)\n",
    "        self.sample_num = 64 # self.num_of_label ** 2\n",
    "        self.learning_rate_g = 0.000006 * self.I_want_to_train_faster\n",
    "        self.learning_rate_d = 0.000005 * self.I_want_to_train_faster\n",
    "        # beta1 hyperparam for adam\n",
    "        self.adam_beta_1 = 0.5\n",
    "        # beta2 hyperparam for adam\n",
    "        self.adam_beta_2 = 0.999\n",
    "        self.real_label = 1.0\n",
    "        self.fake_label = 0.0\n",
    "        self.syn_criterion = nn.BCELoss().to(device) # synthesizing\n",
    "        self.class_criterion = nn.CrossEntropyLoss().to(device) # classification\n",
    "        \n",
    "        self.train_loader, self.test_loader, self.train_data, self.test_data = self.load_dataset()\n",
    "        self.generator = Generator(self.size_of_z, self.img_size, self.num_of_ch).to(device)\n",
    "        self.discriminator = Discriminator(self.img_size, self.num_of_ch, self.num_of_label).to(device)\n",
    "\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), \n",
    "                                      lr=self.learning_rate_d, \n",
    "                                      betas=(self.adam_beta_1, self.adam_beta_2))\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), \n",
    "                                      lr=self.learning_rate_g, \n",
    "                                      betas=(self.adam_beta_1, self.adam_beta_2))\n",
    "\n",
    "        # fixed noise & label\n",
    "        self.sample_z_fixed = torch.zeros((self.sample_num, self.size_of_z))\n",
    "        for i in range(round(np.sqrt(self.sample_num))):\n",
    "            self.sample_z_fixed[i*round(np.sqrt(self.sample_num))] = torch.rand(1, self.size_of_z)\n",
    "            for j in range(1, round(np.sqrt(self.sample_num))):\n",
    "                self.sample_z_fixed[i*round(np.sqrt(self.sample_num)) + j] = self.sample_z_fixed[i*round(np.sqrt(self.sample_num))]\n",
    "\n",
    "        self.sample_z_fixed.resize_(self.sample_num, self.size_of_z, 1, 1)\n",
    "        temp = torch.zeros((self.num_of_label, 1))\n",
    "        for i in range(self.num_of_label):\n",
    "            temp[i, 0] = i\n",
    "\n",
    "        temp_y = torch.zeros((self.sample_num, 1))\n",
    "        for i in range(self.num_of_label):\n",
    "            temp_y[i*self.num_of_label: (i+1)*self.num_of_label] = temp\n",
    "\n",
    "        self.sample_y_fixed = torch.zeros((self.sample_num, self.num_of_label)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
    "        self.sample_z_fixed, self.sample_y_fixed = self.sample_z_fixed.to(device), self.sample_y_fixed.to(device)\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        train_dir = self.train_path\n",
    "        test_dir = self.test_path\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_data, self.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        test_data = datasets.ImageFolder(test_dir ,transform=transform)\n",
    "        test_loader = DataLoader(test_data, self.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        return train_loader, test_loader, train_data, test_data\n",
    "\n",
    "    def modeltorchviz(model, input_1, input_2):\n",
    "        if input_2 != None:\n",
    "            y = model(input_1.to(device), input_2.to(device))\n",
    "        else:\n",
    "            y = model(input_1.to(device))\n",
    "        if input_2 != None:\n",
    "            MyConvNetVis = make_dot(y, params=dict(list(model.named_parameters()) + [('x', input_1)] + [('x', input_2)]))\n",
    "        else:\n",
    "            MyConvNetVis = make_dot(y, params=dict(list(model.named_parameters()) + [('x', input_1)]))\n",
    "        MyConvNetVis.format = \"png\"\n",
    "        MyConvNetVis.directory = \"images\"\n",
    "        MyConvNetVis.view() \n",
    "    \n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "        self.generator.eval()\n",
    "\n",
    "        image_frame_dim = round(np.sqrt(self.sample_num))\n",
    "        if fix:\n",
    "            \"\"\" fixed noise \"\"\"\n",
    "            samples = self.generator(self.sample_z_fixed)\n",
    "        else:\n",
    "            \"\"\" random noise \"\"\"\n",
    "            sample_y_ = torch.zeros(self.batch_size, self.class_num).scatter_(1, torch.randint(0, self.class_num - 1, (self.batch_size, 1)).type(torch.LongTensor), 1)\n",
    "            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "            sample_z_, sample_y_ = sample_z_.cuda(), sample_y_.cuda()\n",
    "            samples = self.generator(sample_z_, sample_y_)\n",
    "\n",
    "        samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        samples = (samples + 1) / 2\n",
    "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    os.path.join('.', 'GANAug/plots/ACGAN') + \"/\" + self.model_name + '_generate_animation_epoch%03d' % epoch + '.png')\n",
    "    \n",
    "    def train(self):\n",
    "        for func in [\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/model')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/plots')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/model/ACGAN')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/plots/ACGAN')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/output_images')),\n",
    "            lambda: os.mkdir(os.path.join('.', 'GANAug/output_images/ACGAN'))]:\n",
    "            try:\n",
    "                func()\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                continue\n",
    "        matrix_fields = [\n",
    "            'G_losses',\n",
    "            'G_class_losses',\n",
    "            'G_syn_losses',\n",
    "            'D_losses',\n",
    "            'D_real_losses',\n",
    "            'D_fake_losses',\n",
    "            'D_class_losses',\n",
    "            'D_syn_losses',\n",
    "            'Losses',\n",
    "            'Time_per_epoch',\n",
    "            'Total_time'\n",
    "        ]\n",
    "        self.metrics = {field: list() for field in matrix_fields}\n",
    "        early_stop_count = 0\n",
    "        early_stop_patient = len(self.train_loader) * 42\n",
    "        early_stop = False\n",
    "        best_batch_loss = -1\n",
    "        save_model = False\n",
    "        number_of_model_saved = 10\n",
    "        label_fixed_data = [i%self.num_of_label for i in range(self.sample_num)]\n",
    "        \n",
    "        def get_file_list(file_path, length):\n",
    "            dir_list = os.listdir(file_path)\n",
    "            dir_list = only_pth_file(dir_list)\n",
    "            if not dir_list:\n",
    "                return\n",
    "            else:\n",
    "                dir_list = sorted(dir_list,  key=lambda x: os.path.getmtime(os.path.join(file_path, x)))\n",
    "                print(\"files to be deleted < length =\", length ,\"> ->\", dir_list[0:length])\n",
    "                return dir_list[0:length]\n",
    "\n",
    "        def only_pth_file(file_list):\n",
    "            new_list = []\n",
    "            for file in file_list:\n",
    "                if file[-4:] == \".pth\":\n",
    "                    new_list.append(file)\n",
    "            return new_list\n",
    "            \n",
    "        start_time = time.time()\n",
    "        print(\"Start Testing ...\")\n",
    "        print(self.generator)\n",
    "        print(self.discriminator)\n",
    "        summary(self.generator, (self.size_of_z, 1, 1), batch_size=self.batch_size, device=device)\n",
    "        summary(self.discriminator, (self.num_of_ch, self.img_size, self.img_size), batch_size=self.batch_size, device=device)\n",
    "        g_output = self.generator(torch.rand((self.batch_size, self.size_of_z, 1, 1)).to(device))\n",
    "        print(g_output.shape)\n",
    "        s_output, c_output = self.discriminator(torch.rand(g_output.shape).to(device))\n",
    "        print(s_output.shape)\n",
    "        print(c_output.shape)\n",
    "        del g_output, s_output, c_output\n",
    "        print(\"Testing Done in ->\", time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "        print(\"Start Training ...\")\n",
    "\n",
    "        self.discriminator.train()\n",
    "        for epoch in range(self.num_epoch):\n",
    "            epoch += 1\n",
    "            log_in_data_loader = []\n",
    "            self.generator.train()\n",
    "            epoch_start_time = time.time()\n",
    "            for i, data in enumerate(tqdm(self.train_loader, 0)):\n",
    "                x_, y_ = data\n",
    "                batch_size_x_ = x_.size(0)\n",
    "                z_ = torch.rand((batch_size_x_, self.size_of_z, 1, 1))\n",
    "                y_vec_ = torch.zeros((batch_size_x_, self.num_of_label)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
    "                x_, z_, y_vec_ = x_.cuda(), z_.cuda(), y_vec_.cuda()\n",
    "                self.y_real_, self.y_fake_ = torch.ones(batch_size_x_, 1), torch.zeros(batch_size_x_, 1)\n",
    "                self.y_real_, self.y_fake_ = self.y_real_.to(device), self.y_fake_.to(device)\n",
    "        \n",
    "                # update D network\n",
    "                self.optimizer_d.zero_grad()\n",
    "\n",
    "                D_real, C_real = self.discriminator(x_)\n",
    "                D_real_loss = self.syn_criterion(D_real, self.y_real_)\n",
    "                C_real_loss = self.class_criterion(C_real, torch.max(y_vec_, 1)[1])\n",
    "\n",
    "                G_ = self.generator(z_)\n",
    "                D_fake, C_fake = self.discriminator(G_)\n",
    "                D_fake_loss = self.syn_criterion(D_fake, self.y_fake_)\n",
    "                C_fake_loss = self.class_criterion(C_fake, torch.max(y_vec_, 1)[1])\n",
    "\n",
    "                D_loss = D_real_loss + C_real_loss\n",
    "                D_loss.backward()\n",
    "                D_loss = D_fake_loss # + C_fake_loss\n",
    "                self.metrics['D_losses'].append(D_loss.item())\n",
    "                self.metrics['D_real_losses'].append((D_real_loss + C_real_loss).item())\n",
    "                self.metrics['D_fake_losses'].append((D_fake_loss + C_fake_loss).item())\n",
    "                self.metrics['D_class_losses'].append((C_real_loss + C_fake_loss).item())\n",
    "                self.metrics['D_syn_losses'].append((D_real_loss + D_fake_loss).item())\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.optimizer_d.step()\n",
    "\n",
    "                # update G network\n",
    "                self.optimizer_g.zero_grad()\n",
    "\n",
    "                G_ = self.generator(z_)\n",
    "                D_fake, C_fake = self.discriminator(G_)\n",
    "\n",
    "                D_fake_loss = self.syn_criterion(D_fake, self.y_real_)\n",
    "                C_fake_loss = self.class_criterion(C_fake, torch.max(y_vec_, 1)[1])\n",
    "\n",
    "                G_loss = D_fake_loss # + C_fake_loss\n",
    "                self.metrics['G_losses'].append(G_loss.item())\n",
    "                self.metrics['G_syn_losses'].append(D_fake_loss.item())\n",
    "                self.metrics['G_class_losses'].append(C_fake_loss.item())\n",
    "                self.metrics['Losses'].append(self.metrics['G_losses'][-1] + self.metrics['D_losses'][-1])\n",
    "\n",
    "                G_loss.backward()\n",
    "                self.optimizer_g.step()\n",
    "\n",
    "                if best_batch_loss < 0:\n",
    "                    best_batch_loss = self.metrics['Losses'][-1]\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    if best_batch_loss >= self.metrics['Losses'][-1]:\n",
    "                        best_batch_loss = self.metrics['Losses'][-1]\n",
    "                        early_stop_count = 0\n",
    "                        log_in_data_loader.append(\"---------------------<lowest loss update -> \" + str(best_batch_loss) + \" at -> \" + str(i + 1) + \">---------------------\")\n",
    "                        save_model = True\n",
    "                    else:\n",
    "                        early_stop_count += 1\n",
    "                        if early_stop_count >= early_stop_patient:\n",
    "                            log_in_data_loader.append(\"-----------------------------------< early stopping ... >-----------------------------------\")\n",
    "                            early_stop = True\n",
    "\n",
    "                if i == 0:\n",
    "                    vutils.save_image(x_, './GANAug/output_images/ACGAN/real_samples_e' + str(epoch) + '_d' + str(i) + '.jpg', normalize=True)\n",
    "\n",
    "            self.metrics['Time_per_epoch'].append(time.time() - epoch_start_time)\n",
    "#             with torch.no_grad():\n",
    "#                 self.visualize_results(epoch)\n",
    "            fake = self.generator(self.sample_z_fixed)\n",
    "            vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.jpg' % ('./GANAug/plots/ACGAN', epoch), normalize=True)\n",
    "    \n",
    "            for message in log_in_data_loader:\n",
    "                print(message)\n",
    "            print('[%d/%d] ======================================================================== \\nLoss_D: %.8f, Loss_G: %.8f\\nLoss_S_D: %.8f, Loss_C_D: %.8f, Loss_R_D: %.8f, Loss_F_D: %.8f\\nLoss_S_G: %.8f, Loss_C_G: %.8f'\n",
    "                  % (epoch, self.num_epoch, \n",
    "                     np.mean(self.metrics['D_losses'][-len(self.train_loader):]), \n",
    "                     np.mean(self.metrics['G_losses'][-len(self.train_loader):]),\n",
    "                     np.mean(self.metrics['D_syn_losses'][-len(self.train_loader):]), \n",
    "                     np.mean(self.metrics['D_class_losses'][-len(self.train_loader):]), \n",
    "                     np.mean(self.metrics['D_real_losses'][-len(self.train_loader):]), \n",
    "                     np.mean(self.metrics['D_fake_losses'][-len(self.train_loader):]), \n",
    "                     np.mean(self.metrics['G_syn_losses'][-len(self.train_loader):]),\n",
    "                     np.mean(self.metrics['G_class_losses'][-len(self.train_loader):])))\n",
    "\n",
    "            # do checkpointing\n",
    "            if save_model == True:\n",
    "                save_model = False\n",
    "                torch.save(self.generator.state_dict(), '%s/G_epoch_%d_save_model.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "                torch.save(self.discriminator.state_dict(), '%s/D_epoch_%d_save_model.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "            elif early_stop:\n",
    "                torch.save(self.generator.state_dict(), '%s/G_epoch_%d_early_stop.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "                torch.save(self.discriminator.state_dict(), '%s/D_epoch_%d_early_stop.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "                break\n",
    "            elif epoch % round(self.num_epoch/5) == 0:\n",
    "                torch.save(self.generator.state_dict(), '%s/G_epoch_%d.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "                torch.save(self.discriminator.state_dict(), '%s/D_epoch_%d.pth' % (os.path.join('.', 'GANAug/model/ACGAN'), epoch))\n",
    "            else:\n",
    "                print(\"---------------------< no model saved at epoch:\", epoch, \">---------------------\")\n",
    "\n",
    "            if len(only_pth_file(os.listdir(os.path.join('.', 'GANAug/model/ACGAN')))) > number_of_model_saved:\n",
    "                delete_list = get_file_list(os.path.join('.', 'GANAug/model/ACGAN'), \n",
    "                                            len(only_pth_file(os.listdir(os.path.join('.', 'GANAug/model/ACGAN')))) - number_of_model_saved)\n",
    "                for file in delete_list:\n",
    "                    if os.path.exists(os.path.join(os.path.join('.', 'GANAug/model/ACGAN'), file)):\n",
    "                        os.remove(os.path.join(os.path.join('.', 'GANAug/model/ACGAN'), file))\n",
    "                    else:\n",
    "                        print(\"file ->\", os.path.join(os.path.join('.', 'GANAug/model/ACGAN'), file), \"does not exist\")\n",
    "\n",
    "        self.metrics['Total_time'].append(time.time() - start_time)\n",
    "        print(\"Average epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.metrics['Time_per_epoch']),\n",
    "                                                                        self.num_epoch, self.metrics['Total_time'][0]))\n",
    "        generate_animation(os.path.join('.', 'GANAug/plots/ACGAN/') + self.model_name, self.num_epoch)\n",
    "        loss_plot(self.metrics, os.path.join('.', 'GANAug/plots/ACGAN/'), self.model_name + \"_loss_plot\")\n",
    "        print(\"Training Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11433097",
   "metadata": {},
   "outputs": [],
   "source": [
    "acgan = ACGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53308270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing ...\n",
      "Generator(\n",
      "  (ReLU): ReLU(inplace=True)\n",
      "  (Tanh): Tanh()\n",
      "  (conv1): ConvTranspose2d(512, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (BatchNorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): ConvTranspose2d(1024, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      ")\n",
      "Discriminator(\n",
      "  (LeakyReLU): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (DropOut1): Dropout(p=0.5, inplace=False)\n",
      "  (DropOut2): Dropout(p=0.25, inplace=False)\n",
      "  (conv1): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4_1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4_2): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm4_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4_3): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (BatchNorm4_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(1024, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (disc_linear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (aux_linear): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (softmax): LogSoftmax(dim=None)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [64, 1024, 4, 4]       8,388,608\n",
      "       BatchNorm2d-2           [64, 1024, 4, 4]           2,048\n",
      "              ReLU-3           [64, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-4           [64, 1024, 8, 8]      16,777,216\n",
      "       BatchNorm2d-5           [64, 1024, 8, 8]           2,048\n",
      "              ReLU-6           [64, 1024, 8, 8]               0\n",
      "   ConvTranspose2d-7          [64, 512, 16, 16]       8,388,608\n",
      "       BatchNorm2d-8          [64, 512, 16, 16]           1,024\n",
      "              ReLU-9          [64, 512, 16, 16]               0\n",
      "  ConvTranspose2d-10          [64, 256, 32, 32]       2,097,152\n",
      "      BatchNorm2d-11          [64, 256, 32, 32]             512\n",
      "             ReLU-12          [64, 256, 32, 32]               0\n",
      "  ConvTranspose2d-13          [64, 128, 64, 64]         524,288\n",
      "      BatchNorm2d-14          [64, 128, 64, 64]             256\n",
      "             ReLU-15          [64, 128, 64, 64]               0\n",
      "  ConvTranspose2d-16          [64, 3, 128, 128]           6,144\n",
      "             Tanh-17          [64, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 36,187,904\n",
      "Trainable params: 36,187,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 1512.00\n",
      "Params size (MB): 138.05\n",
      "Estimated Total Size (MB): 1650.17\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lebro\\AppData\\Local\\Temp\\ipykernel_23860\\1298441974.py:118: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c = self.softmax(c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [64, 128, 64, 64]           6,144\n",
      "       BatchNorm2d-2          [64, 128, 64, 64]             256\n",
      "         LeakyReLU-3          [64, 128, 64, 64]               0\n",
      "           Dropout-4          [64, 128, 64, 64]               0\n",
      "            Conv2d-5          [64, 256, 32, 32]         524,288\n",
      "       BatchNorm2d-6          [64, 256, 32, 32]             512\n",
      "         LeakyReLU-7          [64, 256, 32, 32]               0\n",
      "           Dropout-8          [64, 256, 32, 32]               0\n",
      "            Conv2d-9          [64, 512, 16, 16]       2,097,152\n",
      "      BatchNorm2d-10          [64, 512, 16, 16]           1,024\n",
      "        LeakyReLU-11          [64, 512, 16, 16]               0\n",
      "          Dropout-12          [64, 512, 16, 16]               0\n",
      "           Conv2d-13           [64, 1024, 8, 8]       8,388,608\n",
      "      BatchNorm2d-14           [64, 1024, 8, 8]           2,048\n",
      "        LeakyReLU-15           [64, 1024, 8, 8]               0\n",
      "          Dropout-16           [64, 1024, 8, 8]               0\n",
      "           Conv2d-17           [64, 1024, 4, 4]      16,777,216\n",
      "      BatchNorm2d-18           [64, 1024, 4, 4]           2,048\n",
      "        LeakyReLU-19           [64, 1024, 4, 4]               0\n",
      "          Dropout-20           [64, 1024, 4, 4]               0\n",
      "           Conv2d-21            [64, 128, 1, 1]       2,097,152\n",
      "           Linear-22                    [64, 3]             387\n",
      "       LogSoftmax-23                    [64, 3]               0\n",
      "           Linear-24                    [64, 1]             129\n",
      "          Sigmoid-25                    [64, 1]               0\n",
      "================================================================\n",
      "Total params: 29,896,964\n",
      "Trainable params: 29,896,964\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 1952.07\n",
      "Params size (MB): 114.05\n",
      "Estimated Total Size (MB): 2078.11\n",
      "----------------------------------------------------------------\n",
      "torch.Size([64, 3, 128, 128])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 3])\n",
      "Testing Done in -> 4.065072059631348\n",
      "Start Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 1/4 [00:02<00:06,  2.00s/it]"
     ]
    }
   ],
   "source": [
    "acgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e18531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gan(acgan):\n",
    "    now = datetime.datetime.now()\n",
    "    g_losses = acgan.metrics['G_losses'][-1]\n",
    "    d_losses = acgan.metrics['D_losses'][-1]\n",
    "    path='GANAug/output_images/ACGAN'\n",
    "    try:\n",
    "        os.mkdir(os.path.join('.', path))\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "    real_batch = next(iter(acgan.train_loader))\n",
    "    \n",
    "    test_img_list = []\n",
    "    test_noise = torch.randn(acgan.batch_size, acgan.size_of_z, device=device)\n",
    "    test_label = torch.randn(acgan.batch_size, acgan.num_of_label, device=device)\n",
    "    test_fake = acgan.generator(test_noise).detach().cpu()\n",
    "    test_img_list.append(vutils.make_grid(test_fake, padding=2, normalize=True))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    ax1 = plt.axis(\"off\")\n",
    "    ax1 = plt.title(\"Real Images\")\n",
    "    ax1 = plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    ax2 = plt.axis(\"off\")\n",
    "    ax2 = plt.title(\"Fake Images\")\n",
    "    ax2 = plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))\n",
    "    plt.show()\n",
    "    fig.savefig('%s/image_%.3f_%.3f_%d_%s.png' %\n",
    "                   (path, g_losses, d_losses, acgan.num_epoch, now.strftime(\"%Y-%m-%d_%H-%M-%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03814c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gan(acgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cca5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gan(name, train_epoch, values, path, save):\n",
    "    clear_output(wait=True)\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    fig = plt.ion()\n",
    "    fig = plt.subplot(1, 1, 1)\n",
    "    fig = plt.title('epoch: %s -> %s: %s' % (train_epoch, name, values[-1]))\n",
    "    fig = plt.ylabel(name)\n",
    "    fig = plt.xlabel('train_set')\n",
    "    fig = plt.plot(values)\n",
    "    fig = plt.grid()\n",
    "    get_fig = plt.gcf()\n",
    "    fig = plt.draw()  # draw the plot\n",
    "    fig = plt.pause(1)  # show it for 1 second\n",
    "    plt.show()\n",
    "    if save:\n",
    "        now = datetime.datetime.now()\n",
    "        get_fig.savefig('%s/%s_%.3f_%d_%s.png' %\n",
    "                        (path, name, train_epoch, values[-1], now.strftime(\"%Y-%m-%d_%H-%M-%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    g_losses = metrics['G_losses'][-1]\n",
    "    d_losses = metrics['D_losses'][-1]\n",
    "    path='GANAug/plots/ACGAN/train_%+.3f_%+.3f_%s'% (g_losses, d_losses, now.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    try:\n",
    "        os.mkdir(os.path.join('.', path))\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    plot_gan('G_losses', num_epochs, metrics['G_losses'], path, True)\n",
    "    plot_gan('D_losses', num_epochs, metrics['D_losses'], path, True)\n",
    "    plot_gan('G_syn_losses', num_epochs, metrics['G_syn_losses'], path, True)\n",
    "    plot_gan('G_class_losses', num_epochs, metrics['G_class_losses'], path, True)\n",
    "    plot_gan('G_syn_losses', num_epochs, metrics['G_syn_losses'], path, True)\n",
    "    plot_gan('D_class_losses', num_epochs, metrics['D_class_losses'], path, True)\n",
    "    plot_gan('D_syn_losses', num_epochs, metrics['D_syn_losses'], path, True)\n",
    "    plot_gan('Losses', num_epochs, metrics['Losses'], path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ad873",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(acgan.generator, acgan.discriminator, acgan.optimizer_g, acgan.optimizer_d, acgan.metrics, acgan.num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cd9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_img_list = []\n",
    "test_noise = torch.randn(acgan.batch_size, acgan.size_of_z, device=device)\n",
    "test_label = torch.randn(acgan.batch_size, acgan.num_of_label, device=device)\n",
    "test_img = acgan.generator(test_noise)\n",
    "\n",
    "s_output, c_label_op = acgan.discriminator(test_img.detach().to(device))\n",
    "print('Discriminator s', s_output)\n",
    "print('Discriminator c', c_label_op)\n",
    "\n",
    "test_img = test_img.detach().cpu()\n",
    "test_img_list.append(vutils.make_grid(test_img, padding=2, normalize=True))\n",
    "plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fe52a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = next(iter(acgan.test_loader))\n",
    "test_noise, test_class_lable = data\n",
    "test_img = test_noise\n",
    "print('class label for real', test_class_lable)\n",
    "\n",
    "s_output,c_label_op = acgan.discriminator(test_img.detach().to(device))\n",
    "print('Discriminator s', s_output)\n",
    "print('Discriminator c', c_label_op)\n",
    "\n",
    "test_img = test_img.detach().cpu()\n",
    "test_img_list.append(vutils.make_grid(test_img, padding=2, normalize=True))\n",
    "plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "550e2c2236fe9503f4897db4f47270808d6dc156a400f12e86205b32d1962744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
